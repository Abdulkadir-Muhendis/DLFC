{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN():\n",
    "    def __init__(self,inputs,outputs,epochs,lr):\n",
    "        self.inputs = inputs\n",
    "        self.outputs =  outputs\n",
    "        self.epochs = epochs\n",
    "        self.input_shape = inputs.shape[1]\n",
    "        self.synaptic_weights = self.random_wegihts()\n",
    "        self.lr = lr\n",
    "        self.mse_ = 0\n",
    "        self.acc = 0\n",
    "        self.predicted_outputs = 0\n",
    "        \n",
    "        \n",
    "    def sigmoid(self,x):\n",
    "        return 1 / (1 + np.exp(-x)) \n",
    "    \n",
    "    def sigmoid_derivative(self,x):\n",
    "        return x * (1 - x)\n",
    "        \n",
    "    def random_wegihts(self):\n",
    "        return 2 * np.random.random((self.input_shape,1)) - 1 \n",
    "    \n",
    "    def accuracy(self,y_pred,y_true):\n",
    "        y_pred = y_pred.round(0).flatten().astype(np.int64)\n",
    "        y_true = y_true.round(0).flatten().astype(np.int64)\n",
    "\n",
    "        correct = 0\n",
    "        len_ = len(y_true)\n",
    "        for i in range(len_):\n",
    "            if y_pred[i]==y_true[i]:\n",
    "                correct += 1\n",
    "        return np.round(float(correct/len_) * 100,2)\n",
    "    \n",
    "    def mse(self,error):\n",
    "        return np.square(error).mean()\n",
    "        \n",
    "\n",
    "    def print_results(self,epoch,y_predict):\n",
    "        print(f'Epoch {epoch}/{self.epochs} -- acc {self.acc} % -- mse  {self.mse_}')\n",
    "        \n",
    "    def summary(self):\n",
    "        print(self.acc)\n",
    "        print(f'MSE : {np.round(self.mse_,5)} -- Accuracy: {self.acc} %')\n",
    "       # return {'acc':self.acc,'mse':self.mse}\n",
    "        \n",
    "    \n",
    "    \n",
    "        \n",
    "    def train(self):\n",
    "        predicted_outputs = 0\n",
    "        weights = 0\n",
    "        \n",
    "        for iter_ in range(self.epochs):\n",
    "            #print('Iter number : ',iter_)\n",
    "            inputs_ = self.inputs\n",
    "            weights = self.synaptic_weights\n",
    "            dot_vectors = np.dot(inputs_,weights)\n",
    "            predicted_outputs = self.sigmoid(dot_vectors)            \n",
    "\n",
    "            # how much did we miss?\n",
    "            error = self.outputs - predicted_outputs \n",
    "            \n",
    "            self.mse_ = self.mse(error)\n",
    "            self.predicted_outputs = predicted_outputs\n",
    "            self.acc = self.accuracy(predicted_outputs,self.outputs)\n",
    "            \n",
    "\n",
    "\n",
    "            # multiply how much we missed by the\n",
    "            # slope of the sigmoid at the values in outputs\n",
    "            adjustments = error * self.sigmoid_derivative(predicted_outputs) * self.lr\n",
    "            #print('adjustments',adjustments)\n",
    "\n",
    "            # update weights \n",
    "            self.synaptic_weights += np.dot(inputs_.T, adjustments)\n",
    "            #print('wegihts +=',np.dot(inputs_.T, adjustments))\n",
    "            self.print_results(iter_,predicted_outputs)\n",
    "            \n",
    "\n",
    "        return predicted_outputs\n",
    "    \n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back Propgation :\n",
    "<img src =\"https://i2.wp.com/www.nmthgiat.com/wp-content/uploads/2018/07/geo.png?w=623&ssl=1\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/200 -- acc 0.0 % -- mse  0.302121390600005\n",
      "Epoch 1/200 -- acc 0.0 % -- mse  0.29979762270632854\n",
      "Epoch 2/200 -- acc 0.0 % -- mse  0.29749387511980513\n",
      "Epoch 3/200 -- acc 0.0 % -- mse  0.29521040714689684\n",
      "Epoch 4/200 -- acc 0.0 % -- mse  0.2929474522343399\n",
      "Epoch 5/200 -- acc 0.0 % -- mse  0.29070521852344616\n",
      "Epoch 6/200 -- acc 0.0 % -- mse  0.2884838894600731\n",
      "Epoch 7/200 -- acc 0.0 % -- mse  0.28628362445428635\n",
      "Epoch 8/200 -- acc 0.0 % -- mse  0.28410455958376934\n",
      "Epoch 9/200 -- acc 0.0 % -- mse  0.28194680833511554\n",
      "Epoch 10/200 -- acc 0.0 % -- mse  0.27981046237727014\n",
      "Epoch 11/200 -- acc 0.0 % -- mse  0.2776955923615519\n",
      "Epoch 12/200 -- acc 0.0 % -- mse  0.27560224874289324\n",
      "Epoch 13/200 -- acc 0.0 % -- mse  0.27353046261716757\n",
      "Epoch 14/200 -- acc 0.0 % -- mse  0.2714802465697344\n",
      "Epoch 15/200 -- acc 0.0 % -- mse  0.26945159553061176\n",
      "Epoch 16/200 -- acc 0.0 % -- mse  0.2674444876319795\n",
      "Epoch 17/200 -- acc 33.33 % -- mse  0.2654588850640278\n",
      "Epoch 18/200 -- acc 33.33 % -- mse  0.2634947349254743\n",
      "Epoch 19/200 -- acc 33.33 % -- mse  0.26155197006539405\n",
      "Epoch 20/200 -- acc 44.44 % -- mse  0.25963050991332237\n",
      "Epoch 21/200 -- acc 44.44 % -- mse  0.2577302612949048\n",
      "Epoch 22/200 -- acc 44.44 % -- mse  0.2558511192306733\n",
      "Epoch 23/200 -- acc 44.44 % -- mse  0.253992967715831\n",
      "Epoch 24/200 -- acc 44.44 % -- mse  0.2521556804792105\n",
      "Epoch 25/200 -- acc 44.44 % -- mse  0.2503391217198517\n",
      "Epoch 26/200 -- acc 44.44 % -- mse  0.2485431468199018\n",
      "Epoch 27/200 -- acc 44.44 % -- mse  0.24676760303279055\n",
      "Epoch 28/200 -- acc 44.44 % -- mse  0.24501233014586343\n",
      "Epoch 29/200 -- acc 44.44 % -- mse  0.24327716111687053\n",
      "Epoch 30/200 -- acc 44.44 % -- mse  0.24156192268390622\n",
      "Epoch 31/200 -- acc 66.67 % -- mse  0.23986643594857954\n",
      "Epoch 32/200 -- acc 66.67 % -- mse  0.23819051693235668\n",
      "Epoch 33/200 -- acc 66.67 % -- mse  0.2365339771061693\n",
      "Epoch 34/200 -- acc 66.67 % -- mse  0.23489662389351437\n",
      "Epoch 35/200 -- acc 66.67 % -- mse  0.2332782611473898\n",
      "Epoch 36/200 -- acc 66.67 % -- mse  0.23167868960151466\n",
      "Epoch 37/200 -- acc 66.67 % -- mse  0.2300977072963727\n",
      "Epoch 38/200 -- acc 66.67 % -- mse  0.22853510998069343\n",
      "Epoch 39/200 -- acc 66.67 % -- mse  0.22699069148905243\n",
      "Epoch 40/200 -- acc 66.67 % -- mse  0.2254642440963249\n",
      "Epoch 41/200 -- acc 66.67 % -- mse  0.22395555884976856\n",
      "Epoch 42/200 -- acc 66.67 % -- mse  0.22246442587954707\n",
      "Epoch 43/200 -- acc 66.67 % -- mse  0.2209906346885292\n",
      "Epoch 44/200 -- acc 66.67 % -- mse  0.21953397442221492\n",
      "Epoch 45/200 -- acc 66.67 % -- mse  0.21809423411965045\n",
      "Epoch 46/200 -- acc 66.67 % -- mse  0.2166712029461959\n",
      "Epoch 47/200 -- acc 66.67 % -- mse  0.21526467040900754\n",
      "Epoch 48/200 -- acc 66.67 % -- mse  0.21387442655608926\n",
      "Epoch 49/200 -- acc 66.67 % -- mse  0.21250026215975457\n",
      "Epoch 50/200 -- acc 66.67 % -- mse  0.21114196888532702\n",
      "Epoch 51/200 -- acc 66.67 % -- mse  0.2097993394458852\n",
      "Epoch 52/200 -- acc 66.67 % -- mse  0.20847216774384084\n",
      "Epoch 53/200 -- acc 66.67 % -- mse  0.20716024900011082\n",
      "Epoch 54/200 -- acc 66.67 % -- mse  0.20586337987162176\n",
      "Epoch 55/200 -- acc 88.89 % -- mse  0.20458135855785736\n",
      "Epoch 56/200 -- acc 88.89 % -- mse  0.2033139848971319\n",
      "Epoch 57/200 -- acc 88.89 % -- mse  0.2020610604532449\n",
      "Epoch 58/200 -- acc 88.89 % -- mse  0.2008223885931421\n",
      "Epoch 59/200 -- acc 88.89 % -- mse  0.19959777455618108\n",
      "Epoch 60/200 -- acc 88.89 % -- mse  0.1983870255155691\n",
      "Epoch 61/200 -- acc 88.89 % -- mse  0.19718995063251366\n",
      "Epoch 62/200 -- acc 88.89 % -- mse  0.19600636110359665\n",
      "Epoch 63/200 -- acc 88.89 % -- mse  0.19483607020185775\n",
      "Epoch 64/200 -- acc 88.89 % -- mse  0.19367889331204277\n",
      "Epoch 65/200 -- acc 88.89 % -- mse  0.1925346479604497\n",
      "Epoch 66/200 -- acc 88.89 % -- mse  0.19140315383977724\n",
      "Epoch 67/200 -- acc 88.89 % -- mse  0.19028423282935814\n",
      "Epoch 68/200 -- acc 88.89 % -- mse  0.18917770901113537\n",
      "Epoch 69/200 -- acc 88.89 % -- mse  0.18808340868171664\n",
      "Epoch 70/200 -- acc 88.89 % -- mse  0.18700116036082154\n",
      "Epoch 71/200 -- acc 88.89 % -- mse  0.185930794796415\n",
      "Epoch 72/200 -- acc 88.89 % -- mse  0.18487214496680193\n",
      "Epoch 73/200 -- acc 88.89 % -- mse  0.18382504607993747\n",
      "Epoch 74/200 -- acc 88.89 % -- mse  0.18278933557019278\n",
      "Epoch 75/200 -- acc 88.89 % -- mse  0.1817648530927968\n",
      "Epoch 76/200 -- acc 88.89 % -- mse  0.18075144051616066\n",
      "Epoch 77/200 -- acc 88.89 % -- mse  0.17974894191227608\n",
      "Epoch 78/200 -- acc 88.89 % -- mse  0.178757203545365\n",
      "Epoch 79/200 -- acc 88.89 % -- mse  0.17777607385894592\n",
      "Epoch 80/200 -- acc 88.89 % -- mse  0.17680540346146814\n",
      "Epoch 81/200 -- acc 88.89 % -- mse  0.1758450451106558\n",
      "Epoch 82/200 -- acc 88.89 % -- mse  0.17489485369669197\n",
      "Epoch 83/200 -- acc 88.89 % -- mse  0.17395468622436283\n",
      "Epoch 84/200 -- acc 88.89 % -- mse  0.17302440179427395\n",
      "Epoch 85/200 -- acc 88.89 % -- mse  0.17210386158323987\n",
      "Epoch 86/200 -- acc 88.89 % -- mse  0.1711929288239432\n",
      "Epoch 87/200 -- acc 88.89 % -- mse  0.17029146878394893\n",
      "Epoch 88/200 -- acc 88.89 % -- mse  0.16939934874415463\n",
      "Epoch 89/200 -- acc 88.89 % -- mse  0.16851643797675006\n",
      "Epoch 90/200 -- acc 88.89 % -- mse  0.1676426077227544\n",
      "Epoch 91/200 -- acc 88.89 % -- mse  0.16677773116919264\n",
      "Epoch 92/200 -- acc 88.89 % -- mse  0.16592168342596872\n",
      "Epoch 93/200 -- acc 88.89 % -- mse  0.16507434150248737\n",
      "Epoch 94/200 -- acc 88.89 % -- mse  0.16423558428407375\n",
      "Epoch 95/200 -- acc 88.89 % -- mse  0.16340529250823307\n",
      "Epoch 96/200 -- acc 88.89 % -- mse  0.16258334874079228\n",
      "Epoch 97/200 -- acc 88.89 % -- mse  0.16176963735195982\n",
      "Epoch 98/200 -- acc 88.89 % -- mse  0.16096404449233692\n",
      "Epoch 99/200 -- acc 88.89 % -- mse  0.160166458068912\n",
      "Epoch 100/200 -- acc 88.89 % -- mse  0.1593767677210655\n",
      "Epoch 101/200 -- acc 88.89 % -- mse  0.15859486479661122\n",
      "Epoch 102/200 -- acc 88.89 % -- mse  0.15782064232789728\n",
      "Epoch 103/200 -- acc 88.89 % -- mse  0.15705399500798853\n",
      "Epoch 104/200 -- acc 88.89 % -- mse  0.15629481916694843\n",
      "Epoch 105/200 -- acc 88.89 % -- mse  0.15554301274823987\n",
      "Epoch 106/200 -- acc 88.89 % -- mse  0.15479847528525867\n",
      "Epoch 107/200 -- acc 88.89 % -- mse  0.1540611078780166\n",
      "Epoch 108/200 -- acc 88.89 % -- mse  0.1533308131699844\n",
      "Epoch 109/200 -- acc 88.89 % -- mse  0.15260749532510895\n",
      "Epoch 110/200 -- acc 88.89 % -- mse  0.15189106000501354\n",
      "Epoch 111/200 -- acc 88.89 % -- mse  0.15118141434639154\n",
      "Epoch 112/200 -- acc 88.89 % -- mse  0.150478466938602\n",
      "Epoch 113/200 -- acc 88.89 % -- mse  0.14978212780147473\n",
      "Epoch 114/200 -- acc 88.89 % -- mse  0.14909230836333157\n",
      "Epoch 115/200 -- acc 88.89 % -- mse  0.14840892143922976\n",
      "Epoch 116/200 -- acc 88.89 % -- mse  0.14773188120943367\n",
      "Epoch 117/200 -- acc 88.89 % -- mse  0.14706110319811846\n",
      "Epoch 118/200 -- acc 88.89 % -- mse  0.14639650425231002\n",
      "Epoch 119/200 -- acc 88.89 % -- mse  0.14573800252106572\n",
      "Epoch 120/200 -- acc 88.89 % -- mse  0.14508551743489723\n",
      "Epoch 121/200 -- acc 88.89 % -- mse  0.14443896968543993\n",
      "Epoch 122/200 -- acc 88.89 % -- mse  0.14379828120536942\n",
      "Epoch 123/200 -- acc 88.89 % -- mse  0.1431633751485679\n",
      "Epoch 124/200 -- acc 88.89 % -- mse  0.1425341758705413\n",
      "Epoch 125/200 -- acc 88.89 % -- mse  0.1419106089090884\n",
      "Epoch 126/200 -- acc 88.89 % -- mse  0.14129260096522267\n",
      "Epoch 127/200 -- acc 88.89 % -- mse  0.1406800798843468\n",
      "Epoch 128/200 -- acc 88.89 % -- mse  0.14007297463768106\n",
      "Epoch 129/200 -- acc 88.89 % -- mse  0.13947121530394446\n",
      "Epoch 130/200 -- acc 88.89 % -- mse  0.13887473305128856\n",
      "Epoch 131/200 -- acc 88.89 % -- mse  0.1382834601194844\n",
      "Epoch 132/200 -- acc 88.89 % -- mse  0.1376973298023601\n",
      "Epoch 133/200 -- acc 88.89 % -- mse  0.13711627643048968\n",
      "Epoch 134/200 -- acc 88.89 % -- mse  0.13654023535413184\n",
      "Epoch 135/200 -- acc 88.89 % -- mse  0.1359691429264166\n",
      "Epoch 136/200 -- acc 88.89 % -- mse  0.1354029364867794\n",
      "Epoch 137/200 -- acc 88.89 % -- mse  0.13484155434464115\n",
      "Epoch 138/200 -- acc 88.89 % -- mse  0.13428493576333153\n",
      "Epoch 139/200 -- acc 88.89 % -- mse  0.13373302094425554\n",
      "Epoch 140/200 -- acc 88.89 % -- mse  0.1331857510113\n",
      "Epoch 141/200 -- acc 88.89 % -- mse  0.13264306799547904\n",
      "Epoch 142/200 -- acc 88.89 % -- mse  0.132104914819816\n",
      "Epoch 143/200 -- acc 88.89 % -- mse  0.1315712352844601\n",
      "Epoch 144/200 -- acc 88.89 % -- mse  0.13104197405203552\n",
      "Epoch 145/200 -- acc 88.89 % -- mse  0.13051707663322104\n",
      "Epoch 146/200 -- acc 88.89 % -- mse  0.1299964893725572\n",
      "Epoch 147/200 -- acc 88.89 % -- mse  0.12948015943447946\n",
      "Epoch 148/200 -- acc 88.89 % -- mse  0.12896803478957497\n",
      "Epoch 149/200 -- acc 88.89 % -- mse  0.12846006420105982\n",
      "Epoch 150/200 -- acc 88.89 % -- mse  0.12795619721147528\n",
      "Epoch 151/200 -- acc 88.89 % -- mse  0.12745638412959967\n",
      "Epoch 152/200 -- acc 88.89 % -- mse  0.12696057601757424\n",
      "Epoch 153/200 -- acc 88.89 % -- mse  0.12646872467823977\n",
      "Epoch 154/200 -- acc 88.89 % -- mse  0.12598078264268178\n",
      "Epoch 155/200 -- acc 88.89 % -- mse  0.1254967031579817\n",
      "Epoch 156/200 -- acc 88.89 % -- mse  0.12501644017517116\n",
      "Epoch 157/200 -- acc 88.89 % -- mse  0.12453994833738741\n",
      "Epoch 158/200 -- acc 88.89 % -- mse  0.12406718296822657\n",
      "Epoch 159/200 -- acc 88.89 % -- mse  0.1235981000602924\n",
      "Epoch 160/200 -- acc 88.89 % -- mse  0.12313265626393807\n",
      "Epoch 161/200 -- acc 88.89 % -- mse  0.12267080887619843\n",
      "Epoch 162/200 -- acc 88.89 % -- mse  0.12221251582990932\n",
      "Epoch 163/200 -- acc 88.89 % -- mse  0.12175773568301265\n",
      "Epoch 164/200 -- acc 88.89 % -- mse  0.1213064276080433\n",
      "Epoch 165/200 -- acc 88.89 % -- mse  0.12085855138179638\n",
      "Epoch 166/200 -- acc 88.89 % -- mse  0.12041406737517107\n",
      "Epoch 167/200 -- acc 88.89 % -- mse  0.11997293654318963\n",
      "Epoch 168/200 -- acc 88.89 % -- mse  0.11953512041518828\n",
      "Epoch 169/200 -- acc 88.89 % -- mse  0.11910058108517739\n",
      "Epoch 170/200 -- acc 88.89 % -- mse  0.1186692812023687\n",
      "Epoch 171/200 -- acc 88.89 % -- mse  0.11824118396186704\n",
      "Epoch 172/200 -- acc 88.89 % -- mse  0.11781625309552357\n",
      "Epoch 173/200 -- acc 88.89 % -- mse  0.11739445286294867\n",
      "Epoch 174/200 -- acc 88.89 % -- mse  0.1169757480426815\n",
      "Epoch 175/200 -- acc 88.89 % -- mse  0.11656010392351411\n",
      "Epoch 176/200 -- acc 88.89 % -- mse  0.11614748629596718\n",
      "Epoch 177/200 -- acc 88.89 % -- mse  0.11573786144391554\n",
      "Epoch 178/200 -- acc 88.89 % -- mse  0.11533119613636061\n",
      "Epoch 179/200 -- acc 88.89 % -- mse  0.11492745761934782\n",
      "Epoch 180/200 -- acc 88.89 % -- mse  0.11452661360802585\n",
      "Epoch 181/200 -- acc 88.89 % -- mse  0.11412863227884645\n",
      "Epoch 182/200 -- acc 88.89 % -- mse  0.11373348226190158\n",
      "Epoch 183/200 -- acc 88.89 % -- mse  0.11334113263339625\n",
      "Epoch 184/200 -- acc 88.89 % -- mse  0.11295155290825404\n",
      "Epoch 185/200 -- acc 88.89 % -- mse  0.11256471303285413\n",
      "Epoch 186/200 -- acc 88.89 % -- mse  0.11218058337789655\n",
      "Epoch 187/200 -- acc 88.89 % -- mse  0.11179913473139418\n",
      "Epoch 188/200 -- acc 88.89 % -- mse  0.11142033829178905\n",
      "Epoch 189/200 -- acc 88.89 % -- mse  0.11104416566119081\n",
      "Epoch 190/200 -- acc 88.89 % -- mse  0.11067058883873535\n",
      "Epoch 191/200 -- acc 88.89 % -- mse  0.11029958021406164\n",
      "Epoch 192/200 -- acc 88.89 % -- mse  0.10993111256090418\n",
      "Epoch 193/200 -- acc 88.89 % -- mse  0.10956515903079983\n",
      "Epoch 194/200 -- acc 88.89 % -- mse  0.10920169314690627\n",
      "Epoch 195/200 -- acc 88.89 % -- mse  0.10884068879793085\n",
      "Epoch 196/200 -- acc 88.89 % -- mse  0.10848212023216718\n",
      "Epoch 197/200 -- acc 88.89 % -- mse  0.10812596205163792\n",
      "Epoch 198/200 -- acc 88.89 % -- mse  0.10777218920634225\n",
      "Epoch 199/200 -- acc 88.89 % -- mse  0.10742077698860507\n"
     ]
    }
   ],
   "source": [
    "# input dataset\n",
    "training_inputs = np.array([[0,0,1],\n",
    "                            [1,1,1],\n",
    "                            [1,0,1],\n",
    "                            [0,1,1],\n",
    "                            [0,1,0],\n",
    "                            [0,1,0],\n",
    "                            [0,1,0],\n",
    "                            [1,1,1],\n",
    "                            [0,1,1]\n",
    "                           \n",
    "                           ])\n",
    "\n",
    "# output dataset\n",
    "training_outputs = np.array([[0,\n",
    "                              1,\n",
    "                              1,\n",
    "                              0,\n",
    "                              0,\n",
    "                              0,\n",
    "                              0,\n",
    "                              1,\n",
    "                              0]]).T\n",
    "\n",
    "\n",
    "nn = NN(training_inputs,training_outputs,200,0.03)\n",
    "outputs = nn.train()\n",
    "predicted_outputs = outputs.round(0).flatten().astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.89\n",
      "MSE : 0.10742 -- Accuracy: 88.89 %\n"
     ]
    }
   ],
   "source": [
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
